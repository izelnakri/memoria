Major experiment #1: Fix this so fetchRelationship() actually returns with dangling reference records

hasMany getter should make adjustments *each* time because hasMany may not be fetched on set AND the result of that fetch currently should return the fetchedData *not* existing references(?)
-> change this, in the meantime, make it on the getter

Question, should it do a fallback retention or not.(Its extra computation so lets remove it for now)(It is still needed because when copied references(one fkey gets removed, other should be still in tact!)

// TODO: In future build a generic param filter/validation throw on unrelated attributes use it for build, find, insert, query. Do this even before the CRUD/requests
// TODO: Make Model.peek({ owner }) should make a Model.peek({ owner_id: x }) query
RESTAdapter should check find() and findAll() requests responses to see the data satisfies the query object because server can return anything

globalThis changed in QUnit v2.9, what to do about it in QUnitX
even if lib/setup/node-js-environment runs, new fetch gets interferred and not mocked(?)
After setting up/changing node-js-environment, make pretender correctly mock the node.js "fetch"

============
model.fetchRelationship() should do bookeeping *AFTER* to all belongsTo records, Does appending but no removal
reverse iteration to maintain the same order as the model that fetchRelationship called on
only effect references that reference directly the model, not the modelReferences.has(possibleReference)
delete extra models, append not existing models
================

// TODO: peek, peekBy and peekAll should return the instances that exists if such instances has no changes(?)
// TODO: should findAll on hasMany append existing possible references(?) no it should represent the fetched values(right?)

// TODO: what happens when you copy over data for HasManyArray? Does it copy over models references to the new copied instance(?)
Key to global optimization HistoryLog(a basis for CRDT), Datalog

-> Embedded relationships should be done seperatedly
model update
-> adapter update
-> adapter memory cache
-> RelationshipDB.cache
-> updateRelationshipsGloballyFromARelationship
-> complex lookup to set this.findRelationshipCacheFor(SourceClass, relationshipName, relationshipType).set(reference, targetModel);

4x(belongs-to-id, has-many-id) Memory, REST, SQLAdapter

// model.changeset -> this will have the metadata, but gets generated lazily
// model.changes -> this will have the actual changes and diffing from the previous source record
// model.revision -> this will have the previous source record(?) very error prone

// instanceMetadata
// So model.revision needs to change, get revision.builtAt, reason, and source, revision(needs to be previous model, test this always)

// Make params use match() internally: Email.findBy({ user: userInstance });

RelationshipUtils.replaceExistingModelFromArray() is not possible because replace first needs to remove it then add it in splice()
Because hasManyArray[someIndex] = aModel; doesnt remove items on its own but replace needs to remove the items in the setter level.
Anyways, more hasMany tracking is ok for now, logic should still work.

// never use propEqual due to recursion inside instances on sql(probably many-to-many bug)

- instance metadata feature:
  - index
  - reason
  - source
  - host
  - origin
  - originator_id
  - builtAt
  - [extraData]

deleteInArray / change / addInArray (should be proxied correctly when reference diff different)

# add benchmark setup
# Removing a relationship form an array
# <C-n> <C-p> to jump hunks, zo, zc
# reasons for artifacts: doc gen, code cov report, .apk builds

.. maybe add errors.has(attr) and errors.remove(attr), errors.errorsFor(attr) AND
errors.add(attr, ['', '', '']);

- Serializer interface
- push interface
- MemoryAdapter should be able to handle string id/bigint columns for increment
- ORM should allow publickey and signatures as ids

- investigate silent Errors within memoria.Server handler context
- make passthrough PASS
- add initializer.js
- rollup -i ./lib/response.js -o response.js -f cjs
- memoria glue [jsonEndpoint]

import { cast, validateLength, validateRequired, foreignKeyConstraint } from 'memoria/changeset'; // instead use class-validator
import { from } from 'memoria/query';

// MODEL API:
import Model from 'memoria/model';

class User extends Model {
  Adapter: MemoryAdapter, // or SQLAdapter, JSONAPIAdapter, JSONAdapter, GraphQLAdapter
  Serializer: ModelSerializer // or JSONSerializer, JSONAPISerializer, GraphQLSerializer

  // Extra examples: customAPIActions:
  confirm = APIAction({
    type: 'POST',
    before() {

    },
    after() {

    }
  })
}

SyncStrategies(after CommitHistory)


Done stuff:
- LazyPromise
- PatternMatching match(value, exp) : boolean
- In-memory DB/Adapter/ORM, timeout & sync(!!)
- Adapter interface
- Dirty Attribute check
- (!) Relationship tracking, reflective relationships
- HasManyArray
- QUnitX universal testing & API
- class static API
- HTTP Server in-browser mocking

Future: datalog, HistoryLog, CRDT, Deno KV Adapter, Changeset/query support
model/src/stores/log/db.ts
